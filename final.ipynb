{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "from evaluate_lanenet_on_tusimple import eval_lanenet\n",
    "from modules.homo_util import homoify\n",
    "from modules.video_util import videoify\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../test_set\"\n",
    "JSON_PATH = \"outputs/json/\"\n",
    "SAVE_DIR = \"outputs/seg_results/\"\n",
    "VID_DIR = \"outputs/vids/\"\n",
    "\n",
    "CONST_IMAGE = (1312, 1312)\n",
    "LANENET_WEIGHTS=\"weights/tusimple_lanenet.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frames_dir = \"../test_set/clips/0531/1492626499813320696\"\n",
    "# frames_dir = \"../test_set/clips/0530/1492626191132352208_0\"\n",
    "frames_dir = \"../test_set/clips/0601/1494452387590928848\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0601_1494452387590928848'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip_num = \"_\".join(frames_dir.split(\"/\")[3:])\n",
    "save_json = os.path.join(JSON_PATH, clip_num + \".json\")\n",
    "vid_path = os.path.join(VID_DIR, clip_num + \".mp4\")\n",
    "clip_num"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detecting Lanes using lanenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting lanes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]2022-12-23 15:38:31.046 | INFO     | evaluate_lanenet_on_tusimple:eval_lanenet:152 - Mean inference time every single image: 0.43883s\n",
      "100%|██████████| 20/20 [00:16<00:00,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lanes detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Detecting lanes\")\n",
    "lanes_json = eval_lanenet(frames_dir, LANENET_WEIGHTS, SAVE_DIR, save_json)\n",
    "print(\"Lanes detected\")\n",
    "lanes_json = OrderedDict(sorted(lanes_json.items(), key=lambda x: int(x[0].split(\"/\")[-1].split(\".\")[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['clips/0601/1494452387590928848/1.jpg', 'clips/0601/1494452387590928848/2.jpg', 'clips/0601/1494452387590928848/3.jpg', 'clips/0601/1494452387590928848/4.jpg', 'clips/0601/1494452387590928848/5.jpg', 'clips/0601/1494452387590928848/6.jpg', 'clips/0601/1494452387590928848/7.jpg', 'clips/0601/1494452387590928848/8.jpg', 'clips/0601/1494452387590928848/9.jpg', 'clips/0601/1494452387590928848/10.jpg', 'clips/0601/1494452387590928848/11.jpg', 'clips/0601/1494452387590928848/12.jpg', 'clips/0601/1494452387590928848/13.jpg', 'clips/0601/1494452387590928848/14.jpg', 'clips/0601/1494452387590928848/15.jpg', 'clips/0601/1494452387590928848/16.jpg', 'clips/0601/1494452387590928848/17.jpg', 'clips/0601/1494452387590928848/18.jpg', 'clips/0601/1494452387590928848/19.jpg', 'clips/0601/1494452387590928848/20.jpg'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lanes_json.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOLO_WEIGHTS = \"../yolov7/yolov7.pt\"\n",
    "YOLO_PATH = \"outputs/yolo\"\n",
    "CONF = 0.25\n",
    "SOURCE = frames_dir\n",
    "IMG_SIZE = 1280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO done\n"
     ]
    }
   ],
   "source": [
    "os.system(f\"python ../yolov7/detect.py --weights {YOLO_WEIGHTS} --source {SOURCE} --conf {CONF} --img-size {IMG_SIZE} --save-txt --project {YOLO_PATH}\")\n",
    "print(\"YOLO done\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Frames ready for video writing\n"
     ]
    }
   ],
   "source": [
    "final_frames = homoify(lanes_json, DATA_PATH, YOLO_PATH, CONST_IMAGE)\n",
    "print(\"Final Frames ready for video writing\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_imgs(frames_dir):\n",
    "    frames = [frames_dir + \"/\" + x for x in os.listdir(frames_dir)]\n",
    "    frames = sorted(frames, key=lambda x: int(x.split(\"/\")[-1].split(\".\")[0]))\n",
    "    frames = [cv2.imread(x) for x in frames]\n",
    "    frames = [cv2.cvtColor(x, cv2.COLOR_BGR2RGB) for x in frames]\n",
    "    return frames\n",
    "\n",
    "def TextingOnImg(const_image_size, num_lanes, num_objs):\n",
    "    black_img = np.zeros(const_image_size, np.uint8)\n",
    "    text1 = \"Textual summary of current scene: \"\n",
    "    text2 = f\"Total number of lanes: {num_lanes}\"\n",
    "    text3 = f\"Total number of objects: {num_objs}\"\n",
    "\n",
    "    black_img = cv2.putText(black_img, text1, (20, 100), cv2.FONT_HERSHEY_PLAIN, 3, (255, 255, 255), 3)\n",
    "    black_img = cv2.putText(black_img, text2, (20, 100 + 50), cv2.FONT_HERSHEY_PLAIN, 3, (255, 255, 255), 3)\n",
    "    black_img = cv2.putText(black_img, text3, (20, 100 + 100), cv2.FONT_HERSHEY_PLAIN, 3, (255, 255, 255), 3)\n",
    "\n",
    "    return black_img\n",
    "\n",
    "def cat_images(top_view, blackImg, instanceSeg, source, max_w, max_h):\n",
    "    canvas = np.zeros((max_h, max_w, 3), np.uint8)\n",
    "    canvas[:source.shape[0], :source.shape[1]] = source\n",
    "    canvas[:instanceSeg.shape[0], source.shape[1]:source.shape[1] + instanceSeg.shape[1]] = instanceSeg\n",
    "    canvas[source.shape[0]:source.shape[0] + top_view.shape[0], :top_view.shape[1]] = top_view\n",
    "    canvas[source.shape[0]:source.shape[0] + blackImg.shape[0], top_view.shape[1]:top_view.shape[1] + blackImg.shape[1]] = blackImg\n",
    "\n",
    "    return canvas\n",
    "\n",
    "def videoify(clip_num, final_frames, vid_path, save_dir, const_image=(1312, 1312)):\n",
    "    laneNetResultsPath = os.path.join(save_dir,clip_num)\n",
    "    instanceSegResultsPath = f\"{laneNetResultsPath}/instance_seg\"\n",
    "    sourceResultsPath = f\"{laneNetResultsPath}/result\"\n",
    "    instanceSeg = read_imgs(instanceSegResultsPath)\n",
    "    source = read_imgs(sourceResultsPath)\n",
    "    instanceSeg = [cv2.resize(x, (1280, 720)) for x in instanceSeg]\n",
    "\n",
    "    max_w = max(CONST_IMAGE[1], instanceSeg[0].shape[1], source[0].shape[1]) * 2\n",
    "    max_h = CONST_IMAGE[0] + source[0].shape[0]\n",
    "\n",
    "    vid = cv2.VideoWriter(vid_path, cv2.VideoWriter_fourcc(*'mp4v'), 4, (max_w, max_h))\n",
    "    for idx in range(len(final_frames)):\n",
    "        top_view = final_frames[idx]['img']\n",
    "        num_lanes = final_frames[idx]['num_lanes']\n",
    "        num_objs = final_frames[idx]['num_objs']\n",
    "        blackImg = TextingOnImg((const_image[0], const_image[1], 3), num_lanes, num_objs)\n",
    "        canvas = cat_images(top_view, blackImg, instanceSeg[idx], source[idx], max_w, max_h)\n",
    "\n",
    "        vid.write(canvas)\n",
    "    vid.release()\n",
    "    \n",
    "    return \"Video Written\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video written in outputs/vids/0601_1494452387590928848.mp4\n"
     ]
    }
   ],
   "source": [
    "videoify(\"/\".join(frames_dir.split(\"/\")[-2:]), final_frames, vid_path, SAVE_DIR, CONST_IMAGE)\n",
    "print(f\"Video written in {vid_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "laneNet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "01d6a066a0ce4a4801ed76504f28ce9c8ac9687025d1b36b63edf41b325c3f8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
